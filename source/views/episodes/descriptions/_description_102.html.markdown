In this episode, we take a look at the tokenization process.

It is a routine that converts BASIC keywords and commands into single-byte values, called tokens.

This happens automatically when we type a new line of a program.

But if we want to inject the program directly into the memory, we need to do tokenize keywords ourselves.

We also learn how to help the KickAssembler compiler determine addresses of labels in complicated situations.